{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import new\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizationMode(Enum):\n",
    "    one_bit = 1\n",
    "    two_bit = 2\n",
    "    \n",
    "def compute_adjustment_factor(input_tensor: torch.Tensor):\n",
    "    absmean_weight = torch.mean(torch.abs(input_tensor))\n",
    "    adjustment_factor = 1e-4 + absmean_weight / 2 # 1e-4 to avoid zero divison error\n",
    "    return adjustment_factor\n",
    "\n",
    "quantization_mode = QuantizationMode.two_bit\n",
    "def compute_2bit_quantized_tensor(input_tensor: torch.Tensor):\n",
    "    twobit_matrix = torch.clip(input=torch.round(input_tensor), min=-1, max=1)\n",
    "    return twobit_matrix\n",
    "\n",
    "def compute_1bit_quantized_tensor(input_tensor: torch.Tensor):\n",
    "    return torch.sign(input_tensor)\n",
    "\n",
    "def compute_quantized_tensor(input_tensor: torch.Tensor):\n",
    "    if quantization_mode == QuantizationMode.two_bit:\n",
    "        return compute_2bit_quantized_tensor(input_tensor)\n",
    "    else:\n",
    "        return compute_1bit_quantized_tensor(input_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4495)\n"
     ]
    }
   ],
   "source": [
    "# generate random matrix 5x5 in pytorch\n",
    "torch.manual_seed(42)\n",
    "input_tensor = torch.randn(5, 5)\n",
    "print(compute_adjustment_factor(input_tensor))\n",
    "\n",
    "weight = torch.randn(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3211,  1.5736, -0.8455,  1.3123,  0.6872],\n",
      "        [-1.0892, -0.3553, -0.9138,  0.8963,  2.2181],\n",
      "        [ 0.5232,  0.3466, -0.1973, -1.0546,  1.2780],\n",
      "        [ 0.1453,  0.2311,  0.0566,  0.4263,  0.5750],\n",
      "        [-0.6417, -2.2064, -0.7508,  2.8140,  0.3598]])\n",
      "----\n",
      "tensor([[ 1.,  1., -1.,  1.,  1.],\n",
      "        [-1., -1., -1.,  1.,  1.],\n",
      "        [ 1.,  1., -0., -1.,  1.],\n",
      "        [ 0.,  1.,  0.,  1.,  1.],\n",
      "        [-1., -1., -1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "weight_adjustment_factor = compute_adjustment_factor(weight)\n",
    "adjusted_weight = weight / weight_adjustment_factor\n",
    "quantized_weight = compute_quantized_tensor(adjusted_weight)\n",
    "\n",
    "\n",
    "# print weight, adjusted weight and quantized weight\n",
    "print(weight)\n",
    "print(\"----\")\n",
    "print(quantized_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitNetLinearLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        bias=False,\n",
    "        quantization_mode: QuantizationMode = QuantizationMode.two_bit,\n",
    "    ):\n",
    "        super(BitNetLinearLayer, self).__init__()\n",
    "        self.binary_layer = True\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = (\n",
    "            nn.Parameter(torch.Tensor(out_features)) if bias is not None else None\n",
    "        )\n",
    "        self.quantization_mode = quantization_mode\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def compute_adjustment_factor(self, input_tensor: torch.Tensor):\n",
    "        absmean_weight = torch.mean(torch.abs(input_tensor))\n",
    "        adjustment_factor = 1e-4 + absmean_weight * 2 + 1e-4\n",
    "        return adjustment_factor\n",
    "\n",
    "    def compute_2bit_quantized_tensor(self, input_tensor: torch.Tensor):\n",
    "        twobit_matrix = torch.clip(input=torch.round(input_tensor), min=-1, max=1)\n",
    "        return twobit_matrix\n",
    "\n",
    "    def compute_1bit_quantized_tensor(self, input_tensor: torch.Tensor):\n",
    "        return torch.sign(input_tensor)\n",
    "\n",
    "    def compute_quantized_tensor(self, input_tensor: torch.Tensor):\n",
    "        if self.quantization_mode == QuantizationMode.two_bit:\n",
    "            return self.compute_2bit_quantized_tensor(input_tensor)\n",
    "        else:\n",
    "            return self.compute_1bit_quantized_tensor(input_tensor)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight_adjustment_factor = self.compute_adjustment_factor(self.weight)\n",
    "        adjusted_weight = self.weight / weight_adjustment_factor\n",
    "\n",
    "        if self.training:\n",
    "            quantized_weight = (\n",
    "                adjusted_weight\n",
    "                + (\n",
    "                    self.compute_quantized_tensor(adjusted_weight) - adjusted_weight\n",
    "                ).detach()\n",
    "            )\n",
    "        else:\n",
    "            quantized_weight = self.compute_quantized_tensor(adjusted_weight)\n",
    "\n",
    "        return F.linear(weight_adjustment_factor * x, quantized_weight, self.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def create_quantized_copy_of_model(\n",
    "    input_model: nn.Module, quantization_mode: QuantizationMode\n",
    "):\n",
    "    model_copy = copy.deepcopy(input_model)\n",
    "    hash_table = {n: m for n, m in model_copy.named_modules()}\n",
    "\n",
    "    for key in list(hash_table.keys()):\n",
    "        if isinstance(hash_table[key], nn.Linear):\n",
    "            new_module = BitNetLinearLayer(\n",
    "                in_features=hash_table[key].in_features,\n",
    "                out_features=hash_table[key].out_features,\n",
    "                bias=hash_table[key].bias is not None,\n",
    "                quantization_mode=quantization_mode,\n",
    "            )\n",
    "            name_chain = key.split(\".\")\n",
    "            parent_module_attr_name = \".\".join(name_chain[:-1])\n",
    "            parent_module = hash_table[parent_module_attr_name]\n",
    "            setattr(parent_module, name_chain[-1], new_module)\n",
    "    for n, m in model_copy.named_modules():\n",
    "        assert not isinstance(m, nn.Linear)\n",
    "    return model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import lightning as L\n",
    "from transformers.models.vit.configuration_vit import ViTConfig\n",
    "from transformers.models.vit.modeling_vit import ViTModel, ViTForImageClassification\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "config = ViTConfig(\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=4,\n",
    "    intermediate_size=256,\n",
    "    hidden_act=\"gelu\",\n",
    "    image_size=28,\n",
    "    patch_size=4,\n",
    "    num_labels=10,\n",
    "    num_channels=1,\n",
    ")\n",
    "\n",
    "\n",
    "class ViTImageClassifier(L.LightningModule):\n",
    "    def __init__(self, config: ViTConfig, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = ViTForImageClassification(config)\n",
    "        self.config = config\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(**batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self(batch)\n",
    "        loss = output.loss\n",
    "        argmax = output.logits.argmax(dim=1)\n",
    "        accuracy = (argmax == batch[\"labels\"]).float().mean()\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"tl\": loss.item(),\n",
    "                \"ta\": accuracy.item(),\n",
    "            },\n",
    "            prog_bar=True,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        with torch.no_grad():\n",
    "            output = self(batch)\n",
    "            loss = output.loss\n",
    "            argmax = output.logits.argmax(dim=1)\n",
    "            accuracy = (argmax == batch[\"labels\"]).float().mean()\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"vl\": loss.item(),\n",
    "                \"va\": accuracy.item(),\n",
    "            },\n",
    "            prog_bar=True,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"fashion_mnist\")\n",
    "\n",
    "image_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5), (0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "processed_dataset = dataset.map(\n",
    "    lambda x: {\"pixel_values\": image_transforms(x[\"image\"]), \"labels\": x[\"label\"]}\n",
    ")\n",
    "processed_dataset = processed_dataset.remove_columns([\"label\", \"image\"])\n",
    "processed_dataset.set_format(\"torch\", columns=[\"pixel_values\", \"labels\"])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(processed_dataset[\"train\"], batch_size=128)\n",
    "eval_dataloader = DataLoader(processed_dataset[\"test\"], batch_size=128)\n",
    "\n",
    "normal_model = ViTImageClassifier(config)\n",
    "one_bit_quantized_model = create_quantized_copy_of_model(\n",
    "    normal_model, quantization_mode=QuantizationMode.one_bit\n",
    ")\n",
    "two_bit_quantized_model = create_quantized_copy_of_model(\n",
    "    normal_model, quantization_mode=QuantizationMode.two_bit\n",
    ")\n",
    "\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "\n",
    "# normal_f_mnist\n",
    "normal_logger = WandbLogger(project=\"BitNet\", name=\"normal_f_mnist\")\n",
    "normal_trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=normal_logger,\n",
    ")\n",
    "normal_trainer.fit(\n",
    "    normal_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=eval_dataloader,\n",
    ")\n",
    "\n",
    "\n",
    "# one_bit_f_mnist\n",
    "\n",
    "one_bit_logger = WandbLogger(project=\"BitNet\", name=\"one_bit_f_mnist\")\n",
    "one_bit_trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=one_bit_logger,\n",
    ")\n",
    "one_bit_quantized_model.lr = 1e-4\n",
    "one_bit_trainer.fit(\n",
    "    one_bit_quantized_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=eval_dataloader,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
